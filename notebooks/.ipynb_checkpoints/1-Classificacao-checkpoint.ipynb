{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a0261d",
   "metadata": {},
   "source": [
    "# Classificação\n",
    "\n",
    "A tarefa de **classificação** consiste em predizer **rótulos** para determinados **objetos**. Vamos contextualizar de maneira operacional esses objetos e rótulos através de seus tipos de variáveis: em geral um rótulo é um número inteiro <code>(int)</code> ou uma string <code>(str)</code>; já o objeto a ser classificado pode ser uma imagem, um áudio, ou, de maneira mais geral, um **vetor de features** - aqui vetor tem o mesmo sentido de uma variável lista <code>(lst)</code> ou uma tupla <code>(tuple)</code>. \n",
    "\n",
    "Diferentes **algoritmos de classificação** podem ser usados para realizar essa tarefa de, dada uma entrada (objeto a ser classificado), gerar uma saída (rótulo predito para aquele objeto).\n",
    "\n",
    "Define-se a classificação como uma tarefa de **aprendizado de máquina supervisionado**, isto é, os algoritmos de classificação precisam ser treinados com pares objeto-rótulo tidos como associações corretas. Somente após o treinamento é que o algoritmo de classificação estará apto a predizer rótulos para novas entradas (das quais não se sabe o rótulo a princípio) - diz-se que  algoritmo aprendeu o padrão nos dados de treinamento e agora pode ser usado para classificar novas entradas.\n",
    "\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346659e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No google colab é preciso atualizar a versão do matplotlib para gerar alguns detalhes nas imagens\n",
    "#!pip install matplotlib --upgrade "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b31739",
   "metadata": {},
   "source": [
    "## 1 - MAGIC Gamma Telescope Data Set\n",
    "\n",
    "#### Descrição geral:\n",
    "O problema consiste na detecção de raios gama primários usando um Telescópio de Radiação Cherenkov baseado em solo.\n",
    "Os dados foram gerados por Monte Carlo (com parâmetros para gerar energias menores do que 50 GeV), simulando registros de eventos de raios gama e background. Os registros são imagens de chuveiros de partículas (shower image) que permitem distinguir entre raios gama (sinal alvo) ou imagens de chuveiros hadronicos iniciados por partículas cósmicas no topo da atmosfera (background). A imagens foram pré-processadas para gerar atributos (features) que as caracterizam.\n",
    "\n",
    "#### Objetivo:\n",
    "Prover um meio de software para auxiliar na detecção de partículas gama. O modelo que iremos treinar pode ser usado como um software de um instrumento de medida ou um software para auxiliar na análise de um grande volume de dados.\n",
    "\n",
    "\n",
    "#### Features (variáveis de entrada):\n",
    "As features foram extraídas de processamentos feitos sobre as imagens. São elas:\n",
    "- **fLength**: major axis of ellipse [mm]\n",
    "- **fWidth**: minor axis of ellipse [mm]\n",
    "- **fSize**: 10-log of sum of content of all pixels [in #phot]\n",
    "- **fConc**: ratio of sum of two highest pixels over fSize [ratio]\n",
    "- **fConc1**: ratio of highest pixel over fSize [ratio]\n",
    "- **fAsym**: distance from highest pixel to center, projected onto major axis [mm]\n",
    "- **fM3Long**: 3rd root of third moment along major axis [mm]\n",
    "- **fM3Trans**: 3rd root of third moment along minor axis [mm]\n",
    "- **fAlpha**: angle of major axis with vector to origin [deg]\n",
    "- **fDist**: distance from origin to center of ellipse [mm]\n",
    "\n",
    "#### Classes (rótulos de saída):\n",
    "- g = gamma (signal)\n",
    "- h = hadron (background) \n",
    "\n",
    "#### Referências:\n",
    "Diversos artigos foram públicads baseados nesses dados. Vamos nos ater a dois repositórios de dados secundários e ao artigo original:\n",
    "- https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope\n",
    "- https://www.openml.org/search?type=data&sort=runs&id=1120&status=active\n",
    "- Bock, R.K., Chilingarian, A., Gaug, M., Hakl, F., Hengstebeck, T., Jirina, M., Klaschka, J., Kotrc, E., Savicky, P., Towers, S., Vaicilius, A., Wittek W. (2004). Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope. Nucl.Instr.Meth. A, 516, pp. 511-528 (https://www.sciencedirect.com/science/article/abs/pii/S0168900203025051?via%3Dihub)\n",
    "- Uma imagem de telescópio Cherenkov pode ser vista aqui https://arxiv.org/pdf/2110.14527.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fae7ba",
   "metadata": {},
   "source": [
    "### 1 - Primeiro passo: entendendo os dados (Análise Exploratória)\n",
    "\n",
    "Importando as bibliotecas que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13627b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml # Para importar os dados do site OpenML\n",
    "import pandas as pd                       # Para trabalhar com tabelas\n",
    "import seaborn as sns                     # Para gerar gráficos\n",
    "import matplotlib.pyplot as plt           # Para gerar gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee87856",
   "metadata": {},
   "source": [
    "Buscando os dados no repositório online (OpenML):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef511dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = fetch_openml(data_id=1120)  # Estamos passando o id dos dados e salvando o resultado na variável dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23797b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dados) # A variável dados é do tipo Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.keys() # Aqui estão as chaves (campos) contidas na variável dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a14c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dados.data) # Dentro do campo 'data' da váriavel dados, temos um objeto tipo DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.data.head() # Por ser um objeto tipo DataFrame ele possui os métodos de um dataframe como o .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dados.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7797d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.target # Aqui temos as classes alvo de cada detecção"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae1cf6",
   "metadata": {},
   "source": [
    "Vamos juntar todas as informações em uma única tabela (DataFrame) para facilitar as análises subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dados.data.copy()  # Copiando os dados em uma variável df (o copy gera um novo um objeto e não só uma referência)\n",
    "df['class'] = dados.target.copy() # Criando uma coluna que recebe o campo target da variável dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc889c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28937e",
   "metadata": {},
   "source": [
    "Agora vamos gerar estatísticas básicas dados dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99786ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Nos diz informações gerais sobre a tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50282f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Nos diz estatísticas básicas de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a63028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').mean() # Média de cada feature agrupada pela classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').std() # Desvio padrão de cada feature agrupada pela classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91626b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dispersões par a par de todas as variáveis, e distribuições de cada variável, coloridas pela classe\n",
    "# Pode demorar alguns minutos para executar\n",
    "# sns.pairplot(df, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59ae28",
   "metadata": {},
   "source": [
    "Calculando a correlação entre cada par de variáveis de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.corr(method = 'pearson'), annot=True, fmt=\".1f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a204b5",
   "metadata": {},
   "source": [
    "### 1 - Segundo passo: separar os dados\n",
    "\n",
    "Para o aprendizado supervisionado queremos separar os dados entre dados de entrada (features) e dados de saída (classe alvo), mas também entre **dados de treinamento** e **dados de teste**. Os dados de treinamento são fornecidos aos pares (entrada/saída) para o algoritmos aprender o padrão. Com os dados de teste iremos fornecer apenas as entradas e comparar as saídas preditas pelo algoritmo treinado com as saídas que já sabiamos - isso nos dirá quanto que o algoritmo está acertando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo as colunas de entrada x e as colunas de saída y\n",
    "x = df.drop(columns = ['class']) # Estamos dropando (jogando fora) a coluna class (perceba que é a saida)\n",
    "y = df['class'] # Classe alvo\n",
    "\n",
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 8, stratify=y)\n",
    "\n",
    "# O parâmetro stratify mantem a mesma proporção de exemplos para cada classe\n",
    "# O parâmetro test_size determinado quantos porcento dos dados serão usados para teste\n",
    "# O parâmetro random_state é um seed de número pseudoaleatório usado para gerar a sequência de linhas das tabela \n",
    "# que será de treinamento e aquelas que serão de teste, i.e., estamos separando a tabela de forma aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3060df",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test) # Vendo a quantidade de linhas em cada conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3a3df",
   "metadata": {},
   "source": [
    "### 1 - Terceiro passo: transformar os dados \n",
    "\n",
    "Alguns algoritmos de aprendizado de máquina funcionam melhor quando cada uma das features de entrada está na mesma escala. Por exemplo, digamos que tenhamos duas colunas de entrada sobre duas medidas importantes para o nosso problema, mas uma medida é feita em km e a outra em mm (uma diferença de 6 ordens de magnitude): alguns algoritmos irão estimar que a importância da entrada em km é maior do que da entrada em mm (podendo inclusive desprezar essa entrada). Para evitar isso, podemos adicionar uma etapa de transformação de escalonamento dos dados.\n",
    "\n",
    "Existem várias formas de escalonar os dados, sendo as duas mais usadas a **Padronização** (standardization) e a **Normalização** (normalization).\n",
    "\n",
    "Para mais informações sobre tipos de escalonamento, consulte:\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "\n",
    "Algoritmos cujo escalonamento dos dados de entrada pode ser importante:\n",
    "- K-nearest neighbors\n",
    "- Logistic regression\n",
    "- SVM\n",
    "- Perceptrons e redes neurais artificiais\n",
    "\n",
    "Algoritmos invariantes a escalonamento da entrada:\n",
    "- Fisher LDA\n",
    "- Naive Bayes\n",
    "- Decision trees\n",
    "- RandomForest\n",
    "- GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b830bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o Escalonador\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Treinando o escalonador\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# Usando o escalonador treinado para transformar os dados\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d8c52",
   "metadata": {},
   "source": [
    "### 1 -  Quarto passo: treinar o algoritmo \n",
    "\n",
    "Devemos escolher um algoritmo de classificação (existem vários!).\n",
    "Consulte https://scikit-learn.org/stable/supervised_learning.html#supervised-learning para saber mais sobre os classificadores disponíveis na biblioteca Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55655c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos o objeto do classificador (não mudamos nenhum hiperpârametro)\n",
    "classificador_lr = LogisticRegression()  \n",
    "\n",
    "# Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "classificador_lr.fit(x_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b41662",
   "metadata": {},
   "source": [
    "### 1 - Quinto passo: testar e avaliar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f30a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25715324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceba que estamos passando apenas o x de teste, afinal o algoritmo é que nos dira qual é o y \n",
    "y_predicoes_lr = classificador_lr.predict(x_test_scaled) \n",
    "\n",
    "# Alguns algoritmos soltam, além dos rótulos, um valor de confiança entre 0 e 1 naquele rótulo predito\n",
    "confidence_lr = classificador_lr.predict_proba(x_test_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicoes_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence[::,0] # Pegar apenas o primeiro elemento de cada par de probabilidade\n",
    "#confidence[::,1] # Pegar apenas o segundo elemento de cada para de probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1eff8",
   "metadata": {},
   "source": [
    "A matriz de confusão nos dá uma forma de verificar visualmente como os acertos e erros do classificador estão distribuídos entre as classes.\n",
    "- True Label é o rótulo verdadeiro que sabiamos de antemão;\n",
    "- Predicted Label é o rótulo predito pelo classificador (que gostaríamos que fosse igual ao rótulo verdadeiro). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367552f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes_lr,\n",
    "                                   labels=['g','h'])\n",
    "\n",
    "# plotando uma figura com a matriz de confusao\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao, display_labels=['g','h'])\n",
    "disp.plot(values_format='d') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a719ecb",
   "metadata": {},
   "source": [
    "A partir dos quadrantes na matriz de confusão podemos calcular algumas métricas:\n",
    "- **Precisão** é a quantidade de acertos do classificador para a classe alvo (neste caso, a classe g) levando-se em consideração **tudo que foi predito como dentro do escopo**. É calculado pela divisão $\\frac{TP}{TP+FP}$\n",
    "- **Revocação** é a quantidade de acertos para a classe dentro do escopo levando-se em consideração **tudo que deveria ter sido predido dentro do escopo**. É calculada pela divisão $\\frac{TP}{TP+FN}$\n",
    "- **F1-Score** é a média harmônica entre a precisão e a revocação.\n",
    "- **Acurácia** é a razão entre a quantidade de acertos e a quantidade de erros do classificador $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "- **Suporte** é a quantidade de exemplos em cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f873316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica do Coeficiente Kappa de Cohen nos diz quão distante o classificador está de um classificador aleatório\n",
    "cohen_kappa_score(y_test, y_predicoes_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a19608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_label é o label da classe que está no nosso escopo, aquela que queremos descobrir\n",
    "# Perceba que estamos pegando as probabilidades referentes ao mesmo label\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, confidence_lr[::,0], pos_label='g')\n",
    "\n",
    "# A integral da curva ROC nos diz quão bom o classificador for em discernir as duas classes\n",
    "auc_lr = roc_auc_score(y_test, confidence_lr[::,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_lr,tpr_lr)\n",
    "plt.ylabel('True Positive Rate'), plt.xlabel('False Positive Rate')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='grey')   # Reta de probabilidade 1/2 (jogar moeda)\n",
    "plt.xlim([0,1]), plt.ylim([0,1])                      # Limites do gráfico\n",
    "plt.text(0.8,0.1,f'AUC={str(round(auc_lr,3))}')       # Valor da integral da ROC\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabf132",
   "metadata": {},
   "source": [
    "### 1 - Voltando para o passo 4\n",
    "Como podemos melhorar o classificador?\n",
    "Várias alternativas são possíveis:\n",
    "- **Seleção de Features**: escolher quais atributos de entrada usaremos;\n",
    "- **Pré-processamento das entrada**: os dados tem outliers? Quão bons são os dados usados?\n",
    "- **Transformações das entrada**: mudar escalonamento ou outras técnicas de transformação;\n",
    "- **Comparar Algoritmos**: testar outros algoritmos para a mesma tarefa;\n",
    "- **Ajuste de Hiperparâmetros**: modificar os hiperparâmetros de um algoritmo para melhorar sua performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edbbb0",
   "metadata": {},
   "source": [
    "Vamos fazer um teste com uma Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro passo: carregar dados\n",
    "# Não precisamos refazer\n",
    "\n",
    "# Segundo passo: separar dados\n",
    "# Não precisamos refazer \n",
    "\n",
    "# Terceiro passo: transformar dados\n",
    "# Não precisamos refazer\n",
    "\n",
    "# Quarto passo: treinar algoritmo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classificador_rf= RandomForestClassifier() \n",
    "classificador_rf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Quinto passo: testar\n",
    "y_predicoes_rf = classificador_rf.predict(x_test_scaled) \n",
    "confidence_rf = classificador_rf.predict_proba(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8655718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicoes_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ae0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(y_test, y_predicoes_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, confidence_rf[::,0], pos_label='g')\n",
    "auc_rf = roc_auc_score(y_test, confidence_rf[::,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d634ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression  AUC_LG={str(round(auc_lr,3))}')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest         AUC_RF={str(round(auc_rf,3))}')\n",
    "plt.ylabel('True Positive Rate'), plt.xlabel('False Positive Rate')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='grey') # Reta de probabilidade 1/2 (jogar moeda)\n",
    "plt.xlim([0,1]), plt.ylim([0,1])                    # Limites do gráfico\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbaecb",
   "metadata": {},
   "source": [
    "O modelo usando algoritmo de RandomForest obteve um desempenho melhor do que o modelo de Regressão Logística!\n",
    "\n",
    "Podemos retornar os passos para tentar melhorá-lo ainda mais: mas qual seria nossa meta? Em geral, quando estamos comparando desempenho de modelos de Aprendizado de Máquina é uma boa prática ter um **modelo base** como referência, isto é, uma métrica de performance que representa o estado da arte atual ou a situação atual do sistema que estamos melhorando.\n",
    "\n",
    "Vamos assumir que o desempenho obtido é suficiente para nossos propósitos (convidamos os alunos a explorarem as outras possibilidades de aperfeiçoamento como um exercício), e prosseguir com novos pontos sobre modelos de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04822770",
   "metadata": {},
   "source": [
    "### 1 - Sexto passo: uso e deployment do modelo\n",
    "\n",
    "Uma vez que o modelo está treinado e com uma métrica de desempenho aceitável, podemos aplicá-lo para um objetivo específico.\n",
    "\n",
    "Por exemplo, podemos testá-lo para uma entrada genérica (lembre-se que as entradas estão escalonadas de acordo com nosso procedimento adotado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_lr.predict([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "Um dos possíveis usos de alguns modelos de aprendizado de máquina é gerar insights sobre o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848f1a5",
   "metadata": {},
   "source": [
    "Podemos usar o modelo treinado para classificar qualquer nova entrada. Assim, temos uma pergunta operacional para responder agora:\n",
    "\n",
    "Como podemos usar o modelo treinado sem ter que repetir todos os passos anteriores da próxima vez?\n",
    "\n",
    "Dentro do código o modelo está alocado em uma variável, por exemplo <code>classificador_rf</code>. Essa variável na verdade é uma estrutura (objeto) na memória RAM do computador. Uma vez que pararmos de rodar nosso código, o modelo treinado se perde (e teremos começar desde o passo um de novo).\n",
    "\n",
    "Então queremos serializar o modelo, isto é, passá-lo da memória volátil para a memória permanente do computador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77e7cf",
   "metadata": {},
   "source": [
    "Alguns modelos são paramétricos e possuem uma estrutura matemática explicita, como uma equação. Treinar o modelo, neste caso, significa encontrar os coeficientes dessa equação. Vejamos a Regressão Linear:\n",
    "\n",
    "### $p(\\pmb{x})=\\frac{1}{1+e^{-(\\pmb{aX}+b)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13661b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os coeficientes a estão no atributo .coef_ do objeto classificador devidamente treinado\n",
    "classificador_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ce183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O coeficiente linear está no atributo .intercept_ do objeto classificador devidamente treinado\n",
    "classificador_lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793e211",
   "metadata": {},
   "source": [
    "Dessa forma, tendo os coeficientes e equação que rege o algoritmo, podemos reconstruir o modelo a qualquer momento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9be044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(x,a,b):\n",
    "    t = np.inner(x,a)+b\n",
    "    proba = 1/(1+np.exp(-t))\n",
    "    \n",
    "    y_pred = []\n",
    "    for yi in proba:\n",
    "        if yi>=0.5:\n",
    "            y_pred.append('h')\n",
    "        else:\n",
    "            y_pred.append('g')\n",
    "    \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564acc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg(x_test_scaled,classificador_lr.coef_,classificador_lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicoes_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa57aa4",
   "metadata": {},
   "source": [
    "Perceba que isso significa que uma forma de armazenar o modelo de Regressão Logística na memória permanente do computador é definir a equação (método) como feito na função <code>log_reg</code> acima e salvar os valores do coeficientes.\n",
    "\n",
    "De vez de fazer isso manualmente, podemos utilizar funções prontas que realizam essa tarefa.\n",
    "\n",
    "Para serializar objetos na memória em Python pudemos utilizar o formato <code>.pickle</code>, como abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos salvar em bytes (flag wb) para ser mais cross-platform (acessível a vários sistemas)\n",
    "with open('meu_modelo_serializado.pickle', 'wb') as f: \n",
    "    pickle.dump(classificador_lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26628e37",
   "metadata": {},
   "source": [
    "Pronto! Nosso modelo está salvo. Se quisermos usá-lo em um código em Python, podemos simplesmente carregá-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d71909",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meu_modelo_serializado.pickle', 'rb') as f:\n",
    "    modelo_carregado = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_carregado.predict([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.55]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fabdf",
   "metadata": {},
   "source": [
    "Além do formato <code>.pickle</code> é possível exportar o modelo treinado usando um módulo da própria biblioteca do ScikitLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(classificador_lr, 'meu_modelo_serializado.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_carregado2 = load('meu_modelo_serializado.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab58695",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_carregado2.predict([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.55]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1195073",
   "metadata": {},
   "source": [
    "A vantagem de salvar o modelo permanentemente em um arquivo <code>.pickle</code> ou <code>.joblib</code> é que ele pode ser exportado para outros sistemas, inclusive disponibilizado para outras pessoas utilizarem. Na comunidade de IA modelos disponibilizados assim são chamados de **modelos pré-treinados**.\n",
    "\n",
    "Perceba que a persistência feita dessa forma é válida inclusive para modelos não paramétricos como as RandomForest (que precisam armazenar a sequência de perguntas if/else que melhor separam os dados, como uma árvore de decisão - e não coeficientes e um equação como a regressão logística que vimos acima).\n",
    "\n",
    "Outra importante vantagem é que alguns modelos podem levar dias ou semanas para serem treinados. Retreiná-los para cada um dos usos não faria sentido!\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471633a",
   "metadata": {},
   "source": [
    "## 2 - IArpi Data Set\n",
    "\n",
    "#### Descrição geral:\n",
    "Três diferentes objetos são postos a se mover em um plano inclinado devido a ação da gravidade. Atributos cinemáticos do movimento dos corpos são coletados. Pretende-se estabelecer uma relação entre esses atributos e cada tipo de objeto.\n",
    "\n",
    "#### Objetivo:\n",
    "O problema consiste na classificação de três objetos (esfera, cilindro e aro) a partir de atributos cinemáticos do seu movimento em um plano inclinado. O objetivo é introduzir técnicas de IA para cursos de graduação de física onde o experimento do plano inclinado é amplamente estudado (de maneira teórica e em laboratório).\n",
    "\n",
    "\n",
    "#### Features (variáveis de entrada):\n",
    "As features foram determinadas experimentalmente:\n",
    "- Ângulo: ângulo de inclinação do plano [°]\n",
    "- Distância:  distância percorrida pelo objeto [m]\n",
    "- Altura: de partida do objeto [m]\n",
    "- Tempo: intervalo de tempo para percorrer a distância [s]\n",
    "- Velocidade Média: velocidade média determinada pela distância/tempo [m/s]\n",
    "\n",
    "#### Classes (rótulos de saída):\n",
    "- esfera\n",
    "- cilindro\n",
    "- aro\n",
    "\n",
    "#### Referências:\n",
    "- https://github.com/simcomat/IArpi\n",
    "- Ferreira, H., Almeida Junior, E. F., Espinosa-García, W., Novais, E., Rodrigues, J. N. B., & Dalpian, G. M. (2022). Introduzindo aprendizado de máquina em cursos de física: o caso do rolamento no plano inclinado. In Revista Brasileira de Ensino de Física (Vol. 44). FapUNIFESP (SciELO). https://doi.org/10.1590/1806-9126-rbef-2022-0214 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94962a50",
   "metadata": {},
   "source": [
    "###  2 - Primeiro passo: entendendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importando a biblioteca pandas com o nome pd\n",
    "import numpy as np   # Trabalhar com vetores e matrizes de números\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Separação treino e teste dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler       # Escalonador\n",
    "\n",
    "# Diferentes algoritmos supervisionados de classificação\n",
    "from sklearn.dummy import DummyClassifier           # Modelo base\n",
    "from sklearn.neighbors import KNeighborsClassifier  # k-vizinhos mais próximos (KNN)\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # GradientBoosting\n",
    "from sklearn.svm import SVC                         # Maquina de Vetor Suporte SVM\n",
    "from sklearn.neural_network import MLPClassifier    # Multlayer Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB          # Naive Bayes\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "\n",
    "# Métricas de desempenho\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, make_scorer  # Métricas de  Classificacao\n",
    "from sklearn.metrics import confusion_matrix                                # Métricas de Classificacao\n",
    "\n",
    "# Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767f845",
   "metadata": {},
   "source": [
    "Vamos baixar os dados direto do Github do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e722af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados = pd.read_csv('https://raw.githubusercontent.com/simcomat/IArpi/main/datasets/rolling.csv', sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539608ff",
   "metadata": {},
   "source": [
    "### 2 - Segundo passo: separar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b14eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo o que é entrada e o que é saída\n",
    "x = tabela_dados[['Altura (m)','Ângulo (°)', 'Tempo (s)']]  # Features\n",
    "y = tabela_dados['Objeto']                                  # Atributo alvo\n",
    "\n",
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "# Stratify garante que a quantidade de cada objeto seja aproximadamente o mesmo nos conjuntos de treino e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 10, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c1a50",
   "metadata": {},
   "source": [
    "### 2 - Terceiro passo: transformar os dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()   # Instanciando o escalonador\n",
    "scaler.fit(x_train)       # Treinando o escalonador apenas com os dados de treinamento\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)   # Transformando os dados de treinamento pelo escalonador treinado\n",
    "x_test_scaled = scaler.transform(x_test)     # Transformando os dados de teste pelo escalonado treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dc692",
   "metadata": {},
   "source": [
    "### 2 - Quarto passo: treinar o algoritmo\n",
    "\n",
    "Neste caso iremos treinar vários algoritmos diferentes e observar a performance de cada um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2766eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier (Modelo base)\n",
    "base_model = DummyClassifier(strategy=\"uniform\")\n",
    "base_model.fit(x_train_scaled,y_train)\n",
    "\n",
    "# LDA (Discriminante Linear)\n",
    "lda = LinearDiscriminantAnalysis()  # Criando classificador (sem nenhum hiperparametro)\n",
    "lda.fit(x_train_scaled, y_train)    # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# QDA (Discriminante Quadrático)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train_scaled, y_train)\n",
    "\n",
    "# GaussianNB\n",
    "gNB = GaussianNB()\n",
    "gNB.fit(x_train_scaled, y_train)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()     # Criando classificador (sem nenhum hiperparametro)\n",
    "knn.fit(x_train_scaled, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(x_train_scaled, y_train)\n",
    "\n",
    "# MLP \n",
    "mlpc = MLPClassifier(random_state=42)\n",
    "mlpc.fit(x_train_scaled, y_train)\n",
    "# (As iterações de aprendizado podem alcançar o limite default emitindo um warning) \n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestClassifier(random_state=42) # Criando classificador (hiperparametro de seed)\n",
    "rf.fit(x_train_scaled, y_train) #  \n",
    "\n",
    "#Gradient Boosting\n",
    "gboo = GradientBoostingClassifier(random_state=42)\n",
    "gboo.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d84ee",
   "metadata": {},
   "source": [
    "Vamos criar um discionário contendo todos os objetos dos classificadores treinados. Dessa forma, poderemos acessar qualquer um dos modelos através da variável ``` classificacores```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificadores = {\n",
    "    'BM':base_model,\n",
    "    'LDA':lda,\n",
    "    'QDA':qda,\n",
    "    'GNB':gNB,\n",
    "    'KNN':knn,\n",
    "    'SVM':svm,\n",
    "    'RF':rf,\n",
    "    'GB':gboo,\n",
    "    'MLP':mlpc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add95c50",
   "metadata": {},
   "source": [
    "Agora vamos criar variáveis (estruturas dicionário e lista) para armazenar o valor de cada métrica calculada para cada modelo testado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados={}\n",
    "resultados_kappa={}\n",
    "resultados_accuracia={}\n",
    "\n",
    "lab = ['esfera','cilindro','aro']\n",
    "for clf_name, clf in classificadores.items():  # Iterando sobre todos os modelos treinados\n",
    "    y_pred = clf.predict(x_test_scaled)        # Passando para o ML apenas os dados de teste escalonados\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    kappa =  cohen_kappa_score(y_test, y_pred, labels=lab)\n",
    "    \n",
    "    scoring = {'accuracy': acc,\n",
    "               'kappa' :kappa\n",
    "         }\n",
    "    resultados_kappa[clf_name]=kappa\n",
    "    resultados_accuracia[clf_name]=acc\n",
    "    resultados[clf_name]=scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79467c6d",
   "metadata": {},
   "source": [
    "Vamos usar uma estrutura de dados pandas DataFrame para visualizar os dados das métricas que armazenamos no passo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08817d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_teste_classificao = pd.DataFrame(data=resultados)\n",
    "resultado_teste_classificao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb42a4a",
   "metadata": {},
   "source": [
    "### 2 - Comparando com o Modelo Físico\n",
    "\n",
    "Para corpos com simetria radial e massa uniformemente distribuída pode o momento de inércia pode ser expresso por $\\beta mR^2$, onde $m$ é a massa do objeto e $R$ o seu raio. \n",
    "\n",
    "Além disso, considerando que o objeto rola sem deslizar sobre o plano (i.e. há um vínculo entre o movimento de translação do centro de massa e um ponto na superfície de contado do objeto com o plano), então podemos expressar a cinemática desse problema através da velocidade média $V_{med}$ do objeto solto a uma altura $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função recebe a altura, tempo e o ângulo de inclinação e devolve beta predito\n",
    "def encontra_beta(altura, tempo, theta):\n",
    "    g=9.8                                        # Aceleração da gravidade\n",
    "    distancia=altura/np.sin(np.deg2rad(theta))   # Distância percorrida sobre o plano\n",
    "    vmed = distancia/tempo                       # Velocidade média do objeto\n",
    "    beta = (0.5*g*altura/vmed**2)-1\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3378567",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados['Beta MF'] = tabela_dados.apply(lambda x: encontra_beta(x['Altura (m)'],\n",
    "                                                                     x['Tempo (s)'],\n",
    "                                                                     x['Ângulo (°)']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e552601",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536add1",
   "metadata": {},
   "source": [
    "Para comparar, vamos criar uma imagem. Perceba que o modelo físico prevê um valor contínuo e não uma classe. Podemos utilizar uma análise gráfica da distribuição de valores previstos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= knn.predict(x_test_scaled)                # Resultados apenas do KNN\n",
    "matriz_confusao=confusion_matrix(y_test, y_pred)  # Matriz de confusão do KNN\n",
    "result_test=tabela_dados.iloc[x_test.index]       # Pegando apenas as linhas de teste da tabela original (para ver o MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatação da imagem\n",
    "# Definição dos tamanhos de fontes e ticks dos gráficos\n",
    "fsize = 12\n",
    "tsize = 10\n",
    "major = 5.0\n",
    "minor = 3.0\n",
    "\n",
    "style = 'default'\n",
    "plt.style.use(style)\n",
    "\n",
    "#plt.rcParams['text.usetex'] = True  # Para usar fonte tex (precisa instalar o tex antes)\n",
    "plt.rcParams['font.size'] = fsize      \n",
    "plt.rcParams['legend.fontsize'] = tsize\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.size'] = major\n",
    "plt.rcParams['xtick.minor.size'] = minor\n",
    "plt.rcParams['ytick.major.size'] = major\n",
    "plt.rcParams['ytick.minor.size'] = minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1963142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura Classificação\n",
    "fig, axd = plt.subplots(1,2, figsize=(8, 3.5) )\n",
    "\n",
    "\n",
    "# Matriz de Confusao\n",
    "sns.heatmap(matriz_confusao, annot=True, ax=axd[0], cmap=\"YlGn\",\n",
    "            xticklabels=['esfera', 'cilindro', 'aro'], yticklabels=['esfera', 'cilindro', 'aro'],\n",
    "            cbar_kws={'label': 'Quantidade de Exemplos Testados'}, robust=True)\n",
    "axd[0].set_ylabel('Objeto Verdadeiro')\n",
    "axd[0].set_xlabel('Objeto Predito')\n",
    "axd[0].set_title('Aprendizado de Máquina')\n",
    "\n",
    "  \n",
    "# Violinplot\n",
    "sns.violinplot(y='Objeto',x='Beta MF', data=result_test, order =['esfera', 'cilindro', 'aro'],\n",
    "               palette=\"YlGn\", ax=axd[1])\n",
    "axd[1].get_yaxis().set_visible(False)\n",
    "plt.setp(axd[1].get_yticklabels(), visible=False)\n",
    "axd[1].set_xlabel('$\\\\beta$ predito'), axd[1].set_xlim([-0.5,2])\n",
    "axd[1].set_title('Modelo Físico')\n",
    "axd[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd[1].set_ylim([2.5,-0.5])\n",
    "axd[1].plot([0.4,0.4], [-1,3], color='#d5e6ac', linestyle='dashed', linewidth = 1) \n",
    "axd[1].plot([0.5,0.5], [-1,3], color='#81bc82', linestyle='dashed', linewidth = 1) \n",
    "axd[1].plot([1,1], [-1,3], color='#2e7748', linestyle='dashed', linewidth = 1) \n",
    "custom_lines = [Line2D([0], [0], color='#d5e6ac', lw=5),\n",
    "                Line2D([0], [0], color='#81bc82', lw=5),\n",
    "                Line2D([0], [0], color='#2e7748', lw=5)]\n",
    "axd[1].legend(handles=custom_lines, labels=['esfera', 'cilindro', 'aro'],\n",
    "                  title='Objeto Verdadeiro',loc='upper right', frameon=False)\n",
    "\n",
    "# Escrevendo os itens (a), (b), ... em cada um dos gráficos da figura\n",
    "labels_subplots=['(a)','(b)']\n",
    "for i in range(0,2):\n",
    "    if i==0:\n",
    "        trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "        axd[i].text(0.0, 1.0, labels_subplots[i], transform=axd[i].transAxes + trans,\n",
    "                fontsize='medium', verticalalignment='top')\n",
    "    else:\n",
    "        trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
    "        axd[i].text(0.0, 1.0, labels_subplots[i], transform=axd[i].transAxes + trans,\n",
    "                fontsize='medium', verticalalignment='top')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = tabela_dados, x= 'Beta MF', kde=True, hue='Objeto',\n",
    "            palette=['#d5e6ac','#2e7748','#81bc82'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3853d31",
   "metadata": {},
   "source": [
    "### 2 - Validação Cruzada\n",
    "\n",
    "Uma técnica mais avançada de Aprendizado de Máquina é a validação cruzada. Ela tem diversas aplicações e consiste em usar o dataset de maneira alternada, com cada participação servindo para treino e teste em um determinado momento.\n",
    "\n",
    "No nosso caso usaremos essa metodlogia para calcular a **variabilidade do desempenho** dos algoritmos com relação ao conjunto de dados fornecido para **treinamento**. \n",
    "\n",
    "Por hipótese inicial, a distribuição dos dados de treinamento e teste deveriam ser as mesmas (representar amostras da mesma população). Por isso selecionamos de maneira aleatória cada amostra ao separar treino e teste (evitar ordenamento dos valores, por exemplo). Entretanto nossos dados podem representar dados de duas populações distintas (sob a ótica de alguma critério). Se essas distribuições forem muito diferentes, treinar com uma delas e testar com a outra geraria resultados ruins. Esse problema é conhecido como **OOD** - out of (train) distribution.\n",
    "\n",
    "Assim, se nossa variabilidade durante uma validação cruzada for alta, então estamos usandos populações muito distintas em determinados momentos dos nossos testes.\n",
    "\n",
    "**OBS1:** é importante destacar que a Validação Cruzada tem outra aplicação bastante estabelecida na comunidade de Aprendizado de Máquina como metodologia para otimização de hiperparâmetros dos algoritmos. Aqui decidimos introduzir o tópico através de um exemplo mais simples. Para o caso da **otimização de hiperparâmetros**, a validação cruzada garante que o algoritmo treinado não terá visto uma parte do conjunto de dados em nenhum momento do treinamento, permitindo que seja realizado um ajuste fino da performance de cada algoritmo através da escolha dos melhores hiperpârametros de cada um. Uma discussão adicional pode ser obtida aqui https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "**OBS2:** existem situações onde é preciso selecionar amostras ordenadas de vez de amostras aleatórias, por exemplo, para se fazer a predição do próximo valor em uma série temporal. Esse problema é conhecido como **Data Leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold  # Para separar os dados em k folds na classificação\n",
    "from sklearn.model_selection import cross_validate   # Para rodar treinamento e teste sobre kfolds\n",
    "\n",
    "from sklearn import preprocessing          # Auxilia na transformação dos dados (passo 3)\n",
    "from sklearn.pipeline import make_pipeline # Permite realizar uma sequência de processamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60145731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados de entrada e saída para a Classificação\n",
    "x = tabela_dados[['Altura (m)','Ângulo (°)', 'Tempo (s)']]  # Features\n",
    "y = tabela_dados['Objeto']     \n",
    "\n",
    "# Passo 3, 4 e 5 usando PIPELINE\n",
    "#Instanciando os algoritmos\n",
    "base_model = DummyClassifier(strategy=\"uniform\")   # Dummy Classifier\n",
    "lda = LinearDiscriminantAnalysis()                 # LDA (Discriminante Linear)\n",
    "qda = QuadraticDiscriminantAnalysis()              # QDA (Discriminante Quadrático)\n",
    "gNB = GaussianNB()                                 # GaussianNB\n",
    "knn = KNeighborsClassifier()                       # KNN\n",
    "svm = SVC()                                        # SVM\n",
    "mlpc = MLPClassifier(random_state=42)              # MultiLayer Percpetron \n",
    "rf = RandomForestClassifier(random_state=42)       # RandomForest\n",
    "gboo = GradientBoostingClassifier(random_state=42) # Gradient Boosting\n",
    "\n",
    "# Estamos setando um pipeline que envolve escalonar os dados usando MinMax e depois treinar o algoritmo passado\n",
    "classificadores = {\n",
    "    'BM':make_pipeline(preprocessing.MinMaxScaler(), base_model),\n",
    "    'LDA':make_pipeline(preprocessing.MinMaxScaler(), lda),\n",
    "    'QDA':make_pipeline(preprocessing.MinMaxScaler(), qda),\n",
    "    'GNB':make_pipeline(preprocessing.MinMaxScaler(), gNB),\n",
    "    'KNN':make_pipeline(preprocessing.MinMaxScaler(), knn),\n",
    "    'SVM':make_pipeline(preprocessing.MinMaxScaler(), svm),\n",
    "    'RF':make_pipeline(preprocessing.MinMaxScaler(), rf),\n",
    "    'GB':make_pipeline(preprocessing.MinMaxScaler(), gboo),\n",
    "    'MLP':make_pipeline(preprocessing.MinMaxScaler(), mlpc)\n",
    "}\n",
    "\n",
    "# Setando as métricas de desempenho\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'kappa': make_scorer(cohen_kappa_score)}\n",
    "\n",
    "# Rodandos as validações cruzadas\n",
    "results = [] \n",
    "for clf_name, clf in classificadores.items():\n",
    "    \n",
    "    # Separando 5 folds garantimos usar 20% dos dados para teste e 80% para treinamento\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    tmp = cross_validate(clf, x, y, cv=cv, scoring=scoring)   \n",
    "    tmp['clf'] = clf_name\n",
    "    \n",
    "    results.append(tmp) \n",
    "    \n",
    "# Organizando os resultados\n",
    "# Calculando a média e o desvio padrão de cada métrica\n",
    "ob={\n",
    "    'classificador':[],\n",
    "    'accuracy':[],\n",
    "    'accuracy_std':[],\n",
    "    'kappa':[],\n",
    "    'kappa_std':[]\n",
    "}\n",
    "for i in range(0, len(results)):\n",
    "    ob['classificador'].append(results[i]['clf'])\n",
    "    ob['accuracy'].append(np.mean(results[i]['test_accuracy']))\n",
    "    ob['accuracy_std'].append(np.std(results[i]['test_accuracy']))\n",
    "    ob['kappa'].append(np.mean(results[i]['test_kappa']))\n",
    "    ob['kappa_std'].append(np.std(results[i]['test_kappa']))\n",
    "\n",
    "df_class = pd.DataFrame(data= ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f25867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e57e3",
   "metadata": {},
   "source": [
    "Fazendo uma figura para comparar os resultados visualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura Validação Cruzada Classificação e Regressão\n",
    "fig, axd = plt.subplots(2,1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "# Gráficos de barras de comparação dos métodos\n",
    "sns.barplot(x='classificador',y = 'accuracy', data=df_class,\n",
    "            ax=axd[0], color='#81BC82', edgecolor='grey' )\n",
    "sns.barplot(x='classificador',y = 'kappa', data=df_class,\n",
    "            ax=axd[1], color='#81BC82', edgecolor='grey' )\n",
    "\n",
    "axd[0].set_xlabel(''),\n",
    "axd[1].set_xlabel('Algoritmos de Classificação')\n",
    "axd[0].set_ylabel('Acurácia'), axd[0].set_ylim([0,1])\n",
    "axd[1].set_ylabel('$\\kappa$ de Cohen'), axd[1].set_ylim([0,1])\n",
    "axd[0].set_yticks([0, 0.5, 1])\n",
    "axd[1].set_yticks([0, 0.5, 1])\n",
    "axd[0].bar_label(axd[0].containers[0], rotation=90, label_type='center', color='w', fmt='%.2f')\n",
    "axd[1].bar_label(axd[1].containers[0], rotation=45, label_type='edge', color='k', fmt='%.2f')\n",
    "\n",
    "# Barras verticais indicando variabilidade pelo desvio padraõ\n",
    "x_coords = [p.get_x() + 0.5 * p.get_width() for p in axd[0].patches]\n",
    "y_coords = [p.get_height() for p in axd[0].patches]\n",
    "axd[0].errorbar(x=x_coords, y=y_coords, yerr=df_class['accuracy_std'], fmt=\"none\", c=\"r\", capsize=0.1)\n",
    "\n",
    "x_coords = [p.get_x() + 0.5 * p.get_width() for p in axd[1].patches]\n",
    "y_coords = [p.get_height() for p in axd[1].patches]\n",
    "axd[1].errorbar(x=x_coords, y=y_coords, yerr=df_class['kappa_std'], fmt=\"none\", c=\"r\", capsize=0.1)\n",
    "\n",
    "\n",
    "plt.setp(axd[0].get_xticklabels(), visible=False)\n",
    "axd[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Escrevendo os itens (a), (b)\n",
    "labels_subplots=['(a)','(b)']\n",
    "for i in range(0,2):\n",
    "    trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
    "    axd[i].text(0.0, 1.0, labels_subplots[i], transform=axd[i].transAxes + trans,\n",
    "            fontsize='medium', verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd95fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
