{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d6b003",
   "metadata": {},
   "source": [
    "# Agrupamento, Redução de Dimensionalidade e Processamento de Linguagem Natural \n",
    "\n",
    "A tarefa de **agrupamento** consiste em predizer grupos para determinados objetos (como listas de features). \n",
    "\n",
    "Os algoritmos de agrupamento são ditos de **aprendizado de máquina não supervisionado** pois os grupos dos objetos não são conhecidos *a priori* como no caso da classificação. Por isso, em geral, o agrupamento tende a ser menos acurado do que a classificação. Perceba, contudo, que o agrupamento pode ser feito quando não são conhecidos rótulos, ou seja, durante uma etapa **descritiva** da análise de dados. A classificação, por possuir rótulos é definida como **preditiva** no sentido de predizer as classes de objetos quando as classes já são conhecidas.\n",
    "\n",
    "A tarefa de **redução de dimensionalidade** consiste em diminuir a dimensão da representação de determinados objetos, por exemplo, diminuir um objeto representado por uma lista de 10 features e um novo objeto com uma lista de 5 features.\n",
    "\n",
    "Existem muitas técnicas de redução de dimensionalidade. Etapas de **seleção de features** podem ser entendidas como redução de dimensionalidade supervisionada quando aplicados algoritmos de regressão ou classificação sobre um loop de performance, isto é, quando uma técnica supervisionada é usada para avaliar o desempenho de um método preditivo conforme se varia o número de features do problema. Também podemos aplicar técnicas **não supervisionadas** que visam encontrar novas variáveis que são combinações da variáveis originais, como em uma projeção. Outra técnica usada para reduzir a dimensão da representação dos dados é denominada **autoencoder**.\n",
    "\n",
    "**Processamento de Linguagem Natural** (Natural Language Processing) é toda uma área da computação interessada e criar métodos computacionais para processar textos escritos por seres humanos. Apesar de existirem esforços da comunida de Inteligência Artificial para produzir sistema de NLP mais precisos, iremos tentar demonstrar nos exemplos aqui tratados como uma área diversa pode ser usada para a física no contexto de **Mineração de Texto**. Contudo, vale destacar que não é somente nessa perspectiva que ambas as disciplinas podem se ajudar: novas técnicas de NLP podem se valer de conceitos matemáticos físicos e sistemas que expressam raciocinío podem aprender leis física expressas em linguagem natural (seja para restrições do modelo ou como resultados do modelo). Novas possibilidades podem surgir da pesquisa ativa da junção desses dois campos. \n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273a896",
   "metadata": {},
   "source": [
    "Importando bibliotecas para gráficos e setando alguns parâmetros gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb70878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para gerar gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1944423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros gerais para os gráficos\n",
    "# Definição dos tamanhos de fontes e ticks dos gráficos\n",
    "fsize = 12\n",
    "tsize = 10\n",
    "major = 5.0\n",
    "minor = 3.0\n",
    "\n",
    "style = 'default'\n",
    "plt.style.use(style)\n",
    "\n",
    "#plt.rcParams['text.usetex'] = True  # Para usar fonte tex (precisa instalar o tex antes)\n",
    "plt.rcParams['font.size'] = fsize      \n",
    "plt.rcParams['legend.fontsize'] = tsize\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.size'] = major\n",
    "plt.rcParams['xtick.minor.size'] = minor\n",
    "plt.rcParams['ytick.major.size'] = major\n",
    "plt.rcParams['ytick.minor.size'] = minor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6cb0dc",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "## 0 - Dados Introdutórios\n",
    "\n",
    "Antes de tentarmos reproduzir os resultados de artigos científicos, vamos entender um pouco mais das técnicas de **Agrupamento** com dados sintéticos e de outros domínios (imagens). Nosso objetivo será apresentar os conceitos relevantes do Aprendizado de Máquina não Supervisionado envolvidos nessa tarefa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982da8e",
   "metadata": {},
   "source": [
    "### 0 - Grupos em dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para gerar dados sintéticos\n",
    "from sklearn.datasets import make_blobs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035e7ce",
   "metadata": {},
   "source": [
    "Vamos criar um conjunto de dados de exemplo com 1000 amostras, distribuídas ao longo de 5 centros distintos:\n",
    "- Em <code>x</code> temos os valores das features (descritores).\n",
    "- Em <code>y_true</code> temos os grupos reais. Já que estamos gerando os dados, nós sabemos quais são os grupos. Entretanto, em uma situação real, não temos essa informação, por isso usamos um método de ML não supervisionado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2037e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true = make_blobs(n_samples=1000, centers=5, n_features=2,  random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ca7d9",
   "metadata": {},
   "source": [
    "Podemos observar os dados criados em um gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7393a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos de Agrupamento\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3288c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os algoritmos de clusterização\n",
    "km = KMeans(n_clusters=5, random_state=42)                   # Estamos setando o número de grupos esperados para 5\n",
    "ac = AgglomerativeClustering(n_clusters=5, linkage='ward')   # Estamos setando o número de grupos esperados para 5\n",
    "db = DBSCAN(eps=0.5, min_samples=20)                         # Nesta técnica não setamos o número de grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f51326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando os algoritmos de clusterização nos dados\n",
    "# Perceba que, a princípio, não existe separação treino/teste na tarefa não supervisionada\n",
    "kmeans_labels = km.fit_predict(x)  \n",
    "hierarquico_labels = ac.fit_predict(x)  \n",
    "dbscan_labels = db.fit_predict(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b30b5",
   "metadata": {},
   "source": [
    "Pronto! Encontramos um rótulo (grupo) para os dados de maneira não supervisionada (i.e., sem falar antes para o método quais grupos existem e dar exemplos, durante o treinamento, de dados pertencentes a esses grupos.\n",
    "\n",
    "Entretanto, para alguns métodos precisamos dizer quantos grupos nós esperamos. E isso pode ser dificil de estimar em um cenário totalmente exploratório.\n",
    "\n",
    "Por gerarem novas descrições para os dados, as técnicas de Agrupamento também são chamadas de **técnicas descritivas** em contraponto as **técnicas preditivas** das tarefas de classificação e regressão.\n",
    "\n",
    "Como não temos os <code>y_true</code> (em um cenário real!), não podemos calcular a matriz de confusão, acurácia, precisão, etc.. Precisamos utilizar outras técnicas. Existem algumas métricas de desempenho, como métricas de desempenho externas (que comparam dois métodos de agrupamentos distintos para ver se eles concordam com os grupos encontrados) e métricas de desempenho internas (que tentam estimar se o grupo encontrado divide bem o espaço de pontos dos exemplos original). Vejamos como calcular duas delas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e94999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliacao de desemepnho\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(x, kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adace450",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(x, hierarquico_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5252442",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(x, dbscan_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d967d44",
   "metadata": {},
   "source": [
    "O <code>silhouette_score</code> é uma métrica interna que mede a distância média dos dados intracluster e a distância dos dados entre os clusters. Da forma como é definida, ela favorece medidas radiais.\n",
    "\n",
    "O valor obtido pode estar de -1 a 1, sendo 1 o melhor resultado.\n",
    "\n",
    "Já o <code>adjusted_rand_score</code> calcular se os agrupamentos encontrados por um método são iguais aos agrupamentos encontrados por outro método. Novamente, quanto mais próximo de 1, mais os dois métodos concordam entre si com os grupos encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(kmeans_labels, hierarquico_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(kmeans_labels, dbscan_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(hierarquico_labels, dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30a55f",
   "metadata": {},
   "source": [
    "Esta análise nos dá que o kmeans e o cluster hierarquico chegaram nos mesmos agrupamentos. Como temos dados bidimensionais, podemos plotar um gráfico e observar os grupos no espaço:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02376fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(10, 5))\n",
    "\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1],  ax=ax[0][0])\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=kmeans_labels,  ax=ax[0][1], legend=False)\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=hierarquico_labels,  ax=ax[1][0], legend=False)\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=dbscan_labels,  ax=ax[1][1], legend=False)\n",
    "\n",
    "ax[0][0].set_title('Original')\n",
    "ax[0][1].set_title('KMeans')\n",
    "ax[1][0].set_title('Cluster Hierarquico')\n",
    "ax[1][1].set_title('DBSCAN')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79ac14",
   "metadata": {},
   "source": [
    "Vejamos o mesmo exemplo com outros dados sintéticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Gerar dados em forma de meia-lua (moons)\n",
    "x, y_true = make_moons(n_samples=1000, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d872a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os algoritmos de clusterização\n",
    "km = KMeans(n_clusters=2, random_state=42)                   # Estamos setando o número de grupos esperados para 2\n",
    "ac = AgglomerativeClustering(n_clusters=2, linkage='ward')   # Estamos setando o número de grupos esperados para 2\n",
    "db = DBSCAN(eps=0.12)                         # Nesta técnica não setamos o número de grupos\n",
    "\n",
    "# Aplicando os algoritmos de clusterização nos dados\n",
    "# Perceba que, a princípio, não existe separação treino/teste na tarefa não supervisionada\n",
    "kmeans_labels = km.fit_predict(x)  \n",
    "hierarquico_labels = ac.fit_predict(x)  \n",
    "dbscan_labels = db.fit_predict(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3329d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(10, 5))\n",
    "\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1],  ax=ax[0][0])\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=kmeans_labels,  ax=ax[0][1], legend=False)\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=hierarquico_labels,  ax=ax[1][0], legend=False)\n",
    "sns.scatterplot(x = x[:,0], y = x[:,1], hue=dbscan_labels,  ax=ax[1][1], legend=False)\n",
    "\n",
    "ax[0][0].set_title('Original')\n",
    "ax[0][1].set_title('KMeans')\n",
    "ax[1][0].set_title('Cluster Hierarquico')\n",
    "ax[1][1].set_title('DBSCAN')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996543a",
   "metadata": {},
   "source": [
    "### 0 - Grupos de pixels em imagens\n",
    "\n",
    "Podemos adaptar essa técnica que encontra **agrupamento no espaço da features** para encotrar **agrupamentos nos espaço dos pixels**. Uma imagem é composta por pixels que representam o nível de intensidade de um determinado canal de cor. Apesar de, tecnicamente, podemos considerar cada pixel de uma imagem como uma **feature**, esse procedimento é muito custoso! Técnicas de ML que processam imagens usam camadas de convolução e pooling para diminuir a quantidade de pixels que é analisada pelo modelo. \n",
    "\n",
    "Para efeitos didáticos, vamos implementar um **Segmentador de Imagens** usando aprendizado de Máquina não Supervisionado de Agrupamento que tenta agrupar os pixels como se eles fossem pontos no espaço de features. Essas técnicas são mais rudimentares mas demonstram uma aplicação distinta do uso de ML não supervisionado:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820856c4",
   "metadata": {},
   "source": [
    "#### Dataset mini-MIAS\n",
    "\n",
    "Vamos usar o dataset mini-MIAS disponível em http://peipa.essex.ac.uk/info/mias.html.\n",
    "\n",
    "Este dataset possui 322 imagens de mamografias, de 1024x1024 pixels.\n",
    "\n",
    "A **Segmentação de Imagem** envolve em colorir de uma mesma cor objetos ou partes de interesse. No caso do nosso dataset, iremos usar a segmentação de imagem para reduzir a resolução, aumentando o contraste entre diferentes regiões dos tecidos representados na imagem de mamografia.\n",
    "\n",
    "O dataset é mais detalhado, possuindo inclusive tipos de câncer e anormalidades que ocorrem em cada uma das imagens.\n",
    "\n",
    "Vamos apenas aplicar o K-Means em algumas imagens para observar o resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para processar arquivos e imagens\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Para plotar imagens\n",
    "import matplotlib.pyplot as plt \n",
    "#import matplotlib.image as mpimg\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.cluster import KMeans # Agrupamento "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd25c81",
   "metadata": {},
   "source": [
    "É necessário baixar algumas das imagens de http://peipa.essex.ac.uk/pix/mias/.\n",
    "\n",
    "Em seguida, suba para a aba de arquivos do Colab ou coloque-as na pasta onde está executando o Jupyter. Atente-se para o caminho relativo das imagens na função <code>imread</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as imagens\n",
    "\n",
    "img_G = mpimg.imread('mias/mdb001.pgm') # Tipo G\n",
    "img_D = mpimg.imread('mias/mdb003.pgm') # Tipo D\n",
    "img_F = mpimg.imread('mias/mdb005.pgm') # Tipo F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as imagens\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "im1 = axs[0].imshow(img_G, cmap='gray', vmin=0, vmax=255)\n",
    "im2 = axs[1].imshow(img_D, cmap='gray', vmin=0, vmax=255)\n",
    "im3 = axs[2].imshow(img_F, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função usa o Kmeans como um filtro de segmentação de imagem\n",
    "\n",
    "def filtro_kmeans(img, clusters):\n",
    "    vectorized = img.reshape((-1,1))\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state = 0, n_init=5)\n",
    "    kmeans.fit(vectorized)\n",
    "    \n",
    "    centers = np.uint8(kmeans.cluster_centers_)\n",
    "    segmented_data = centers[kmeans.labels_.flatten()]\n",
    "    \n",
    "    segmented_image = segmented_data.reshape((img.shape))\n",
    "    return(segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 3\n",
    "\n",
    "img_G_segmentada = filtro_kmeans(img_G, clusters) # Tipo G\n",
    "img_D_segmentada = filtro_kmeans(img_D, clusters) # Tipo D\n",
    "img_F_segmentada = filtro_kmeans(img_F, clusters) # Tipo F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "im1 = axs[0].imshow(img_G_segmentada, cmap='gray', vmin=0, vmax=255)\n",
    "im2 = axs[1].imshow(img_D_segmentada, cmap='gray', vmin=0, vmax=255)\n",
    "im3 = axs[2].imshow(img_F_segmentada, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46254d",
   "metadata": {},
   "source": [
    "A área de **Visão Computacional** é uma área bem ampla e ativa de pesquisa em Ciência da Computação. Diversos desses métodos são implementados em softwares que físicos e cientistas de materiais usam para analisar amostras. \n",
    "\n",
    "Outros exemplos podem ser vistos aqui https://experiencor.github.io/segmentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5650151",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "\n",
    "## 1 - MeltingPoint Dataset\n",
    "\n",
    "#### Descrição geral:\n",
    "São fornecidos dados de compostos orgânicos e seus respectivos pontos de fusão (temperatura de transição entre forma sólida e líquida).\n",
    "\n",
    "#### Objetivo:\n",
    "Prever a temperatura de fusão baseado nas cacaterísticas observadas.\n",
    "\n",
    "#### Features (variáveis de entrada):\n",
    "São fornecidos 202 descritores das moléculas em 2D e 3D.\n",
    "\n",
    "#### Alvo (valor de saída):\n",
    "- Reduzir a dimensionalidade dos dados.\n",
    "\n",
    "#### Referências:\n",
    "- M. Karthikeyan, Robert C. Glen e Andreas Bender, General Melting Point Prediction Based on a Diverse Compound Data Set and Artificial Neural Networks, https://pubs.acs.org/doi/10.1021/ci0500132.\n",
    "- D. Krstajic, L. J Buturovic, D. E. Leahy, e S. Thomas, Cross-validation pitfalls when selecting and assessing regression and classification models, https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-6-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be358307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://pubs.acs.org/doi/suppl/10.1021/ci0500132/suppl_file/ci0500132si20050112_060506.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ci0500132si20050112_060506.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bcc2e",
   "metadata": {},
   "source": [
    "Os dados brutos estão em <code>4137_185_92_DataSetMTPSMIDescr.txt</code>.\n",
    "\n",
    "Já os dados processados pelos autores para gerar uma representação dimensional menor estão em <code>4137_185_92_DataSetMTPPCA1-30.txt</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e39ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82135f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp = pd.read_csv('4137_185_92_DataSetMTPSMIDescr.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65473039",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fe43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315231da",
   "metadata": {},
   "source": [
    "Quando tentamos aplicar a redução de dimensionalidade, percebemos que os dados estão com informações faltando!\n",
    "\n",
    "Logo, não conseguiremos reproduzir exatamente o resultado do artigo, mas podemos preprocessar os dados para gerar nossa própria redução de dimensionalidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp.rename(columns={'$Field_2': 'MTP'}, inplace=True)\n",
    "df_mp.rename(columns={'$Field_1': 'SMILE_Molecule'}, inplace=True)\n",
    "\n",
    "df_mp2 = df_mp.dropna() # Por padrão o dropna() deleta linhas vazias\n",
    "df_mp3 = df_mp2.drop_duplicates(subset=['SMILE_Molecule'], keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a320d3",
   "metadata": {},
   "source": [
    "No artigo original eles usam apenas os descritores denominados 2D para gerar a redução de dimensionalidade e não todas as features apresentadas. Entretanto, não nos é fornecida a lista exata das features que consideram características 3D das moléculas e aquelas que consideram características 2D. \n",
    "\n",
    "Uma possível lista pode ser extraída da Tabela 3 do artigo, considerando a distinção entre denotações em itálico e normal. Contudo, a lista de features obtida assim não equivale a todas as existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fe86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_mp3.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07854f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De acordo com nomes em itálico\n",
    "features_3D=['AM1_E',\n",
    "'AM1_Eele',\n",
    "'MNDO_E', \n",
    "'MNDO_Eele',\n",
    "'PM3_E',\n",
    "'PM3_Eele',\n",
    "'E_vdw',\n",
    "'rgyr',\n",
    "'ASA',\n",
    "'ASA+',\n",
    "'ASA_H',\n",
    "'CASA+',\n",
    "'CASA-',\n",
    "'FCASA+',\n",
    "'VSA',\n",
    "'vol',\n",
    "'ASA_P',\n",
    "'FASA_P',\n",
    "'FASA+',\n",
    "'ASA-',\n",
    "'FASA-'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_nao_considerar = features_3D+['SMILE_Molecule','MTP', 'Case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_mp3.drop(columns=colunas_nao_considerar) # Considerando tudo\n",
    "y = df_mp3['MTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80544b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda96d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=30, svd_solver='full')  # Queremos 30 componentes (usado no artigo)\n",
    "X_pca = pca.fit_transform(x) # Usando dados escalonados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0309e0",
   "metadata": {},
   "source": [
    "Agora vamos carregar os dados do PCA originais do artigo e gerar dois gráficos de comparação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_original = pd.read_csv('4137_185_92_DataSetMTPPCA1-30.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98094d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 5))\n",
    "\n",
    "sns.scatterplot(x = X_pca[:,0], y = X_pca[:,1], hue=df_mp3['Case'], ax=ax[0])\n",
    "sns.scatterplot(data = df_pca_original, x ='PCA1', y ='PCA2', hue='Set', ax=ax[1])\n",
    "\n",
    "for i in range(0,2):\n",
    "    ax[i].set_xlabel('PCA 1')\n",
    "    ax[i].set_ylabel('PCA 2')\n",
    "    ax[i].grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52464",
   "metadata": {},
   "source": [
    "Não conseguimos reproduzir os exatod resultados reportados pelo artigo. Uma possibilidade é tentarmos outra combinação de colunas de entrada para o PCA. Deixamos isso como um exercício para o leitor.\n",
    "\n",
    "\n",
    "O ponto importante a ser notado neste exemplo é que, conseguimos realizar uma projeção de uma espaço de muitas dimensões para um espaço com menos dimensões usando uma técnica de **Aprendizado de Máquina não Supervisionado**. Neste caso, usamos a redução de dimensionalidade apenas para gerar uma visualização, mos podemos tentar entender o que as novas dimensões significam (física e quimicamente, no caso). Também podemos usar esse espaço reduzido como entrada de outros métodos de aprendizado de máquina, para tarefas como **regressão**, **classificação** e **agrupamento**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466c216",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## 2 - Mat2Vec Model\n",
    "\n",
    "#### Descrição geral:\n",
    "Este é um modelo de linguagem para criar vetores numéricos que representam palavras. Ele foi construído a partir do abstract de 3.3 milhões de artigos científicos da área de Materiais. \n",
    "\n",
    "O modelo treinado possui 500k palavras no vocabulário que são codificados em vetores de 200 dimensões (word embedding).\n",
    "\n",
    "#### Objetivo:\n",
    "Utilizar técnicas de aprendizado de máquina não supervisionado de agrupamento e redução de dimensionalidade para encontrar padrões nos dados aprendidos.\n",
    "\n",
    "\n",
    "#### Features (variáveis de entrada):\n",
    "- Embedding da palavra (200 features que capturam a semântica distribuída para representar uma única palavra)\n",
    "\n",
    "#### Alvo (valor de saída):\n",
    "- Embeddings com dimensão menores\n",
    "- Novos grupos nos dados\n",
    "\n",
    "#### Referências:\n",
    "- https://github.com/olivettigroup/materials-word-embeddings\n",
    "- https://github.com/materialsintelligence/mat2vec\n",
    "- Tshitoyan, V., Dagdelen, J., Weston, L., Dunn, A., Rong, Z., Kononova, O., Persson, K. A., Ceder, G., & Jain, A. (2019). Unsupervised word embeddings capture latent knowledge from materials science literature. In Nature (Vol. 571, Issue 7763, pp. 95–98). Springer Science and Business Media LLC. https://doi.org/10.1038/s41586-019-1335-8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb7b2e",
   "metadata": {},
   "source": [
    "### 1 - Instalando o modelo pré-treinado\n",
    "Primeiramente, vamos copiar o repositório do github para nossa máquina (virtual) para que tenhamos acessos aos modelos pré-treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cbce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/materialsintelligence/mat2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d319c7",
   "metadata": {},
   "source": [
    "Vamos instalar as dependências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mat2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907129b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --ignore-installed -rrequirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e67716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec # Biblioteca que carrega os modelos pretreinados dos embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f492b2",
   "metadata": {},
   "source": [
    "Agora vamos carregar o modelo de linguagem pré-treinado e ver o que podemos fazer com ele: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mat2vec = Word2Vec.load(\"mat2vec/training/models/pretrained_embeddings\")\n",
    "mat2vec = Word2Vec.load(\"../../materials_informatics/nlp/mat2vec-master/mat2vec/training/models/pretrained_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = mat2vec.wv.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9444e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vocab) # O vocabulário é um dicionário onde as chaves são as palavras e o conteúdo os embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'H' in list(vocab) # Verificando que o hidrogênio está no vocabulário do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cef739",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = mat2vec.wv['H']\n",
    "print(len(embedding))\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf89fe",
   "metadata": {},
   "source": [
    "### 2 - Gerando uma tabela com os embedding de todos os elementos químicos (até Z=100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_elements = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg',\n",
    "                     'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr',\n",
    "                     'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', \n",
    "                     'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', \n",
    "                     'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', \n",
    "                     'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', \n",
    "                     'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au',\n",
    "                     'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', \n",
    "                     'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72374ba3",
   "metadata": {},
   "source": [
    "Verificando se os elementos estão no vocabulário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_vocab = [chemical for chemical in chemical_elements if chemical in vocab]   \n",
    "len(elements_vocab), len(chemical_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a024e3d",
   "metadata": {},
   "source": [
    "Criando uma tabela para representar essas informações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80813ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = [mat2vec.wv[element] for element in elements_vocab]\n",
    "\n",
    "df_elementos = pd.DataFrame(data=dados)\n",
    "\n",
    "df_elementos['element']=chemical_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd489d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elementos.head(3) # Cada linha é um elementos químico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elementos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8bf17",
   "metadata": {},
   "source": [
    "### 2 - Gerando uma visualização\n",
    "\n",
    "Os dados que temos para representar cada elemento química estão em 200 dimensões. Vamos usar uma técnicade **Aprendizado de Máquina não Supervisionado de Redução de Dimensionalidade** para reduzir para 2 dimensões. Com isso poderemos fazer um plot de dispersão onde cada ponto representará um elemento químico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47743a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para reduzir a dimensionalidade dos dados\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf68999",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_elementos.drop(columns=['element'])\n",
    "y =  df_elementos['element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9562c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, learning_rate=200, perplexity=20, random_state=42)\n",
    "X_tsne = tsne.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.scatterplot(x = X_tsne[:,0], y = X_tsne[:,1])\n",
    "ax.set_xlabel('tsne 1'), ax.set_ylabel('tsne 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eced4e",
   "metadata": {},
   "source": [
    "### 2 - Encontrando grupos \n",
    "\n",
    "Agora vamos aplicar uma técnica **Aprendizado não supervisionado de agrupamento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb14930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elementos['tsne_1'] = X_tsne[:,0]\n",
    "df_elementos['tsne_2'] = X_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_elementos[['tsne_1','tsne_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee19862",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=25, min_samples=2)                       # Nesta técnica não setamos o número de grupos\n",
    "\n",
    "# Aplicando os algoritmos de clusterização nos dados\n",
    "# Perceba que, a princípio, não existe separação treino/teste na tarefa não supervisionada\n",
    "dbscan_labels = db.fit_predict(df_elementos[['tsne_1','tsne_2']])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea67340",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dbscan_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 5))\n",
    "\n",
    "colors = sns.color_palette('Paired', len(set(dbscan_labels)))\n",
    "\n",
    "sns.scatterplot(x = X_tsne[:,0], y = X_tsne[:,1], hue=dbscan_labels, palette=colors, ax=ax[0])\n",
    "\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(0, 1), ncol=2)\n",
    "\n",
    "sns.scatterplot(x = X_tsne[:,0], y = X_tsne[:,1], hue=dbscan_labels, palette=colors, ax=ax[1], legend=False)\n",
    "\n",
    "\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    ax[1].annotate(txt, (X_tsne[i,0], X_tsne[i,1]), fontsize=10)\n",
    "\n",
    "for i in range(0,2):\n",
    "    ax[i].set_xlabel('tsne 1')\n",
    "    ax[i].set_ylabel('tsne 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd837827",
   "metadata": {},
   "source": [
    "### 2 - Descobrindo aplicações de materiais\n",
    "\n",
    "Vamos baixar dados de materiais binários do **Materials Project**. Na sequência, iremos descobrir quantos desses materiais existem no vocabulário do modelo de linguagem **Mat2Vec**. Iremos trabalhar com a intersecção desses dois conjuntos, realizando o mesmo procedimento de redução de dimensionalidade e agrupamento.\n",
    "\n",
    "O **Materials Project** é um repositório de dados de simulações DFT de materiais, majoritariamente sólidos cristalinos inorgânicos. O acesso é gratuito, bastando realizar um cadastro (que pode ser com o gmail).\n",
    "\n",
    "O **pymatgen** é uma biblioteca python para trabalhar com materiais. Ela implementa uma API Rest para se comunicar com o Materials Project, facilitando o download massivo de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea21083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymatgen # Instalando a biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd574e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj  import MPRester # API rester para conexão do o Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critérios de busca na base de dados\n",
    "criteria = {'nelements':{'$in': [2]},           # Somente materiais binarios\n",
    "            #'elements':{'$in':elements},         # Lista de elementos permitidos\n",
    "           } \n",
    "\n",
    "# Propriedades buscadas\n",
    "properties =['material_id', 'icsd_ids', 'pretty_formula','elements', 'band_gap','formation_energy_per_atom',\n",
    "             'e_above_hull', 'spacegroup', 'structure']\n",
    "\n",
    "# Chave de acesso (colocar a sua chave entre as aspas)\n",
    "apikey = '8QLynIvOwGAP5cWH' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamada API rest para requisitar os dados ao servidor do MP\n",
    "with MPRester(apikey) as mpr:\n",
    "    results = mpr.query(criteria, properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c781c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list0 = pd.DataFrame(data = results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrumando a informação na tabela\n",
    "mat_list0[['symprec',\n",
    "          'source',\n",
    "          'symbol',\n",
    "          'number',\n",
    "          'point_group',\n",
    "          'crystal_system',\n",
    "          'hall']] = mat_list0.spacegroup.apply(pd.Series)\n",
    "mat_list0 = mat_list0.drop('spacegroup', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a10b98",
   "metadata": {},
   "source": [
    "Vamos filtrar nossa tabela para pegar somente materiais termodinamicamente estáveis, isto é, aqueles que tem energia de formação negativa e distância do convex hull igual a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42310589",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list1 = mat_list0[(mat_list0['formation_energy_per_atom']<0) & (mat_list0['e_above_hull']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07d11d",
   "metadata": {},
   "source": [
    "Vamos eliminar qualquer entrada duplicada, mantendo a de menor energia de formação (mais estável): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando menor energia de formação\n",
    "mat_list1 = mat_list1.sort_values(by='formation_energy_per_atom')\n",
    "\n",
    "# Deletando duplicados mantendo apenas a primeira ocorrencia\n",
    "mat_list2 = mat_list1.drop_duplicates(subset=['pretty_formula'], keep='first') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat_list0), len(mat_list1), len(mat_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b79ce8",
   "metadata": {},
   "source": [
    "#### Juntando informações do Materials Project e do Mat2Vec\n",
    "Agora vamos criar uma função para retornar o embedding do composto, se o composto estiver no vocabulário do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retornar_embedding(composto):\n",
    "    if composto in vocab:\n",
    "        return mat2vec.wv[composto]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935223c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list2['embedding'] = mat_list2['pretty_formula'].apply(retornar_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list3 = mat_list2.dropna() # Jogando fora as linhas com valores nulos nos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c159d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat_list0), len(mat_list1), len(mat_list2), len(mat_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb45594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempacotando o vetor de embedding em colunas numercadas de 0 a 199\n",
    "mat_list3[[i for i in range(0,200)]] = mat_list3.embedding.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf627ab",
   "metadata": {},
   "source": [
    "#### Separando entradas que iremos passar para os métodos de ML\n",
    "\n",
    "Vamos usar o UMAP como algoritmo de redução de dimensionalidade dessa vez:\n",
    "\n",
    "https://umap-learn.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [i for i in range(0, 200)]\n",
    "x = mat_list3.loc[:, col_names]  # Embedding do Mat2Vec que vou usar como entrada do ML\n",
    "#y = mat_list3['crystal_system']  # Resposta verdadeira de acodor com o Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma instância do UMAP com parâmetros padrão\n",
    "umap_model = umap.UMAP(random_state=42)\n",
    "\n",
    "# Ajustar o modelo UMAP aos dados\n",
    "umap_embeddings = umap_model.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x = umap_embeddings[:, 0], y=umap_embeddings[:, 1], s=20)\n",
    "ax.set_xlabel('umap 1'), ax.set_ylabel('umap 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b65b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list3['umap_1'] = umap_embeddings[:,0]\n",
    "mat_list3['umap_2'] = umap_embeddings[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=[]\n",
    "eps = [0.1,0.2, 0.3, 0.4]\n",
    "min_pts = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for i in eps:\n",
    "    for j in min_pts:\n",
    "        db = DBSCAN(eps=i, min_samples=j)                     \n",
    "        dbscan_labels = db.fit_predict(mat_list3[['umap_1','umap_2']]) \n",
    "        ob={\n",
    "            'eps':i,\n",
    "            'min':j,\n",
    "            'num_grupos':len(set(dbscan_labels))\n",
    "        }\n",
    "        opt.append(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c21917",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.2, min_samples=7)                     \n",
    "dbscan_labels = db.fit_predict(mat_list3[['umap_1','umap_2']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 5))\n",
    "\n",
    "colors = sns.color_palette('Paired', len(set(dbscan_labels)))\n",
    "\n",
    "sns.scatterplot(x = umap_embeddings[:,0], y = umap_embeddings[:,1], palette=colors, ax=ax[0])\n",
    "\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(0, 1), ncol=2)\n",
    "\n",
    "sns.scatterplot(x = umap_embeddings[:,0], y = umap_embeddings[:,1],\n",
    "                hue=dbscan_labels, palette=colors, ax=ax[1], legend=False)\n",
    "\n",
    "#for i, txt in enumerate(y):\n",
    "#    ax[1].annotate(txt, (X_tsne[i,0], X_tsne[i,1]), fontsize=10)\n",
    "\n",
    "for i in range(0,2):\n",
    "    ax[i].set_xlabel('umap 1')\n",
    "    ax[i].set_ylabel('umap 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ef565",
   "metadata": {},
   "source": [
    "Como são técnicas não supervisionadas, não temos certeza sobre a qualidade do resultado quando não temos nenhuma informação adicional.\n",
    "\n",
    "É necessário realizar uma validação posterior ao método de redução de dimensionalidade e agrupamento.\n",
    "\n",
    "Se usamos um método supervisionado, como uma classificação ou uma regressão (sobre os dados com dimsnesão reduzida), caimos sobre um conjunto de técnicas denominadas de **semi-supervisionadas**.\n",
    "\n",
    "É importante notar que as estratégias de aprendizado semi-supervisioado vão além destas desritas acima, por exemplo, usando **Active Learning** para obter rótulos (respostas tidas como corretas) para valiar/retreinar o modelo.\n",
    "\n",
    "Vamos tentar entender o que significam esses grupos encontrados: se tem algum sentido físico ou quimico por trás, ou é apenas um agrupamento espúrio.\n",
    "\n",
    "Primeiro vamos observar as frequências de cada grupo encontrado lembrando que no DBSCAN, <code>label=-1</code> é considerado outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabca7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list3['grupos'] = dbscan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(figsize=(14,4))\n",
    "ax = sns.countplot(x='grupos', data=mat_list3, palette='muted', \n",
    "              order=mat_list3['grupos'].value_counts().index)\n",
    "ax.tick_params(axis='x', labelrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876768f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo_selecionado=mat_list3[mat_list3['grupos']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo_selecionado.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_elementos_grupo=[]\n",
    "for elements in grupo_selecionado['elements']:\n",
    "    todos_elementos_grupo=todos_elementos_grupo+elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd420fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_elementos_grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(14,4))\n",
    "\n",
    "# contar o número de ocorrências de cada categoria\n",
    "counts = pd.Series(todos_elementos_grupo).value_counts()\n",
    "\n",
    "# ordenar as categorias em ordem decrescente e selecionar as 10 primeiras\n",
    "top10_counts = counts.sort_values(ascending=False)[0:10]\n",
    "\n",
    "sns.countplot(x='crystal_system', data=grupo_selecionado, ax=axs[0], palette='muted', \n",
    "              order=grupo_selecionado['crystal_system'].value_counts().index)\n",
    "\n",
    "sns.countplot(x=todos_elementos_grupo, order=top10_counts.index, ax=axs[1], palette='muted')\n",
    "\n",
    "axs[0].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e48ce2",
   "metadata": {},
   "source": [
    "Também podemos usar outros recursos do modelo de linguagem treinado, como a busca por outros embeddings (palavras) que são similares a um determinado compostos do grupo que estamos estudando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2vec.wv.most_similar(\"Ce5O9\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f401a",
   "metadata": {},
   "source": [
    "Ou ainda, procurar uma aplicação ou propriedade física, realizando operações vetoriais sobre os embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PbTe' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ceb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sabendo que PbTe é termolétrico\n",
    "mat2vec.wv.most_similar(\n",
    "    positive=[\"thermoelectric\", \"PbTe\"], \n",
    "    negative=[\"Ce5O9\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb5500",
   "metadata": {},
   "source": [
    "Operando sobre toda a lista de compostos desse agrupamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mat2vec.wv.most_similar(\n",
    "positive=[\"thermoelectric\", \"PbTe\"], \n",
    "negative=[\"Ce5O9\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89686c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=[]\n",
    "for compound in grupo_selecionado['pretty_formula']:\n",
    "    q = mat2vec.wv.most_similar(\n",
    "    positive=[\"thermoelectric\", \"PbTe\"], \n",
    "    negative=[compound], topn=5)\n",
    "    possiveis_aplicacoes = [qi[0] for qi in q if qi[1]>0.5]\n",
    "    #print(possiveis_aplicacoes)\n",
    "    resultados=resultados+possiveis_aplicacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df88186",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b5e43",
   "metadata": {},
   "source": [
    "Podemos agora calcular estatísticas sobre as palavras mais parecidos que estão vindo nos resultados. Como isso podem entender qual poderia ser uma possível aplicação dos materiais pertencentes ao grupo analisado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff82249",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "## Exercícios propostos\n",
    "\n",
    "- No exemplo 2 realizamos redução de dimensionalidade além de carregar os dados da redução de dimensionalidade do artigo original. Tente usar esse novo espaço de representação (gerado pelo nosso PCA e pelo PCA dos autores) como entrada para um regressor, visando predizer a temperatura de fusão. Compare os resultados com os da aula prática 2.\n",
    "\n",
    "- No exemplo 3 realizamos uma busca por aplicações de materiais. Entretanto, na nossa tabela de dados do **Materials Project** temos informações sobre o sistema cristalino do material. O artigo de Tshitoyan et al. diz ser possível usar a mesma operação <code>mat2vec.wv.most_similar()</code> passando exemplos de um cristal com sistema cristalino conhecido e um novo cristalque não sabemos o sistema cristalino. Usando nossa base de dados, separe alguns exemplos para serem as entradas canonicas da analogia (operação vetorial entre os embedding $\\vec{A}+\\vec{B}-\\vec{C}=\\vec{D}$, isto é, os pares de vetores $(\\vec{A},\\vec{B})$ que representam pares conhecidos de fórmula do composto/sistema cristalino. Com o restante dos dados, encontre os sistemas cristalinos ditos pelo Modelo de Linguagem. Compare com as respostas corretas. Refaça o exemplo treinando um algoritmo de classificação, onde a entrada do modelo será o embedding do composto e a saída, o sistema cristalino."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
